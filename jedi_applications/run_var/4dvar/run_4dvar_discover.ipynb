{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcea8c28-fff3-4829-bdc2-47adcecae457",
   "metadata": {},
   "source": [
    "# Running 4DVar application in JEDI (on Discover)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ae065d-50af-436e-87b7-feb5430c7b01",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf5f6bd-03cf-4781-acd4-bdb3fd8dfa90",
   "metadata": {},
   "source": [
    "### Loading Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9d6505-c4a0-4e4c-9afe-9364aa6da920",
   "metadata": {},
   "source": [
    "To Load Spack Stack **1.9** modules with GNU compiler on Discover run:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"Loading EWOK-SKYLAB Environment Using Spack-Stack 1.9.0\"\n",
    "\n",
    "# load modules\n",
    "module purge\n",
    "module use /discover/swdev/gmao_SIteam/modulefiles-SLES15\n",
    "module use /discover/swdev/jcsda/spack-stack/scu17/modulefiles\n",
    "\n",
    "module use /gpfsm/dswdev/jcsda/spack-stack/scu17/spack-stack-1.9.0/envs/ue-gcc-12.3.0/install/modulefiles/Core\n",
    "module load stack-gcc/12.3.0\n",
    "module load stack-openmpi/4.1.6\n",
    "module load stack-python/3.11.7\n",
    "\n",
    "module load singularity\n",
    "\n",
    "# Discover compiler modules set environment variable COMPILER, need to repair for R2D2\n",
    "export COMPILER=gnu\n",
    "\n",
    "module load jedi-fv3-env\n",
    "module load ewok-env\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b93978e",
   "metadata": {},
   "source": [
    "To Load Spack Stack **1.7.0** modules with GNU compiler on Discover run:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"Loading EWOK-SKYLAB Environment Using Spack-Stack 1.7.0 GNU SCU17\"\n",
    "\n",
    "# load modules\n",
    "module purge\n",
    "module use /discover/swdev/gmao_SIteam/modulefiles-SLES15\n",
    "module use /discover/swdev/jcsda/spack-stack/scu17/modulefiles\n",
    "module load ecflow/5.11.4\n",
    "\n",
    "module use /gpfsm/dswdev/jcsda/spack-stack/scu17/spack-stack-1.7.0/envs/ue-gcc-12.3.0/install/modulefiles/Core\n",
    "module load stack-gcc/12.3.0\n",
    "module load stack-openmpi/4.1.6\n",
    "module load stack-python/3.10.13\n",
    "\n",
    "# Discover compiler modules set environment variable COMPILER, need to repair for R2D2\n",
    "export COMPILER=gnu\n",
    "\n",
    "module load jedi-fv3-env\n",
    "module load ewok-env\n",
    "module load sp\n",
    "\n",
    "# To build more expensive fv3-jedi (tier 2) tests\n",
    "#export FV3JEDI_TEST_TIER=2\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Check [here](https://github.com/JCSDA-internal/jedi-tools/blob/develop/buildscripts/setup/discover-mil_setup_gnu.sh) for the latest Spack-Stack modules on Discover. Note that this is a JCSDA private repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f8e1c1-272e-4d5e-a6c6-806d921f3071",
   "metadata": {},
   "source": [
    "To build the `jedi-bundle` follow the [insturctions](https://jointcenterforsatellitedataassimilation-jedi-docs.readthedocs-hosted.com/en/latest/using/running_skylab/running_skylab.html#build-jedi-bundle) here. \n",
    "\n",
    "For a (slightly) faster build, comment out these repos in `jedi-bundle/CMakeLists.txt`: `MOM6`, `soca`, `MPAS-Model`, `mpas-jedi`, and `coupling`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115da74f-72a6-49d9-9937-a61d7df1f9bd",
   "metadata": {},
   "source": [
    "### YAML Structure\n",
    "The JEDI code is under active development, and some of the YAML keys used in the examples may change over time. As a result, this document may become outdated. Itâ€™s important for users to understand both the structure of the YAML files and the meaning of the keys, while also consulting the latest ctest examples in the JEDI repositories.\n",
    "\n",
    "This section provides an overview of the different components within the 4DVar YAML files.\n",
    "\n",
    "`/discover/nobackup/mabdiosk/garage/applications/var-app` includes the YAML files for running different 4dvar cases, the input files, and a run script (`run_4dvar.sh`). \n",
    "\n",
    "`4dvar_geos-cf_fv3lm_c24_p12.yaml` is a 4dvar experiment example at C24 resolution. \n",
    "\n",
    "\n",
    "```yaml\n",
    "cost function:\n",
    "  cost type: 4D-Var\n",
    "  time window:\n",
    "    begin: 2021-08-05T03:00:00Z #always beginning of the window\n",
    "    length: PT6H\n",
    "```\n",
    "\n",
    "In this example, the assimilation window is from `2021-08-05 03Z` to `2021-08-05 09Z`.\n",
    "\n",
    "The beginning of the time window does not depend on the DA method (`cost type`) and is always set to the beginning of the assimilation window.\n",
    "\n",
    "The length of the window is typically set to 6H. \n",
    "\n",
    "---\n",
    "\n",
    "```yaml\n",
    "  model:\n",
    "    name: FV3LM\n",
    "    namelist filename: input/geometry_input/input_geos_c24_p12.nml\n",
    "    tstep: PT15M\n",
    "    filetype: cube sphere history\n",
    "    lm_do_dyn: 1\n",
    "    lm_do_trb: 0\n",
    "    lm_do_mst: 0\n",
    "    model variables: &modelvars [ud,vd,ua,va,T,DELP,SPHU,qi,ql,NO2]\n",
    "```\n",
    "In 4DVar, you need to compute (or pre-compute) the model state at every `tstep` within the assimilation window. Ideally, you want to run the full model and generate the model state at every `tstep`, but this can be costly. To reduce cost, you can 1) compute the model state using a simplified model such as `FV3LM` or 2) read the pre-computed model state using `PSEUDO`). In this example, we are using `FV3LM`. See `4dvar_geos-cf_pseudo.yaml` for a `PSEUDO` example. \n",
    "\n",
    "`FV3LM` model requires `ud,vd,ua,va,T,DELP,SPHU,qi,ql` to be on the `model variables` list (and be available in the background files). Trace gas and aerosol variables can be added to this list and will be treated as tracers (only get transported, similar to moisture). \n",
    "\n",
    "Linear turbulence scheme and linear moist physics are turned off. \n",
    "\n",
    "---\n",
    "\n",
    "```yaml\n",
    "  analysis variables: [eastward_wind,\n",
    "  northward_wind,\n",
    "  air_temperature,\n",
    "  air_pressure_thickness,\n",
    "  specific_humidity,\n",
    "  cloud_liquid_ice,\n",
    "  cloud_liquid_water,\n",
    "  volume_mixing_ratio_of_no2]\n",
    "```\n",
    "The list of variables you want to assimilate. These will be available in the analysis output. Note that the first 7 variables (everything except no2) are required to be on the list.\n",
    "\n",
    "---\n",
    "\n",
    "```yaml\n",
    "  geometry:\n",
    "    fms initialization:\n",
    "      namelist filename: input/geometry_input/fmsmpp.nml\n",
    "    akbk: input/geometry_input/akbk72.nc4\n",
    "    npx: 25\n",
    "    npy: 25\n",
    "    npz: 72\n",
    "    layout: [1,2]\n",
    "    field metadata override: input/geometry_input/geos_cf_ewok.yaml\n",
    "```\n",
    "This section is repeated a few times in this YAML file and always exists in almost all of the JEDI YAML files. Here, you can define the geometry (grid setup) of your background (input) files. We have background files at `C24` resolution with 72 vertical levels.\n",
    "\n",
    "`layout` is another important setting that can change depending on the number of processors you use to run the application. With the layout of `[1,2]` (for each tile), you must use \"1x2x6\" or \"12\" processors (there are 6 tiles in total). If the layout is `[2,2]` you will need \"2x2x6\" or \"24\" processors. \n",
    "\n",
    "`field metadata override` is a list that maps the variables in the background files to JEDI. `long name` in this file refers to the variable name in [fv3-jedi](https://github.com/JCSDA/fv3-jedi/blob/1.8.0/src/fv3jedi/FieldMetadata/FieldsMetadataDefault.h) and `io name` refers to the variable name in the background (input) files. \n",
    "\n",
    "---\n",
    "\n",
    "```yaml\n",
    "  background:\n",
    "    datetime: 2021-08-05T03:00:00Z  #background beginning of the window\n",
    "    filetype: cube sphere history\n",
    "    datapath: input/bg/geoscf_c24_ewok\n",
    "    filename: GCv14.0_GCMv1.17_c24.geoscf_jedi.%yyyy%mm%ddT%hh%MM%ssZ.nc4\n",
    "    state variables: [ud,vd,ua,va,T,SPHU,qi,ql,DELP,NO2,phis]\n",
    "```\n",
    "In 4DVar, the background must be available at the beginning of the assimilation window. \n",
    "\n",
    "`state variables` is the list of variables that JEDI is going to read from the background files and put in \"state\". Anything that is listed under `model variables` must be under `state variables` too. \n",
    "\n",
    "---\n",
    "\n",
    "```yaml\n",
    "  background error:\n",
    "    covariance model: SABER\n",
    "    saber central block:\n",
    "      saber block name: ID\n",
    "```\n",
    "In this example, for simplicity, we are using an Identity matrix for background error. \n",
    "\n",
    "---\n",
    "\n",
    "```yaml\n",
    "  observations:\n",
    "    observers:\n",
    "    - obs space:\n",
    "        name: NO2\n",
    "        obsdatain:\n",
    "          engine:\n",
    "            type: H5File\n",
    "            obsfile: input/obs/obs.tropomi_s5p_no2_tropo.2021-08-05T060000Z.nc4\n",
    "        obsdataout:\n",
    "          engine:\n",
    "            type: H5File\n",
    "            obsfile: output/fb.4dvar.c24.tropomi_s5p_no2_tropo.20210805T060000Z.nc\n",
    "        simulated variables: [nitrogendioxideColumn]\n",
    "      obs operator:\n",
    "        name: ColumnRetrieval\n",
    "        nlayers_retrieval: 34\n",
    "        tracer variables: [volume_mixing_ratio_of_no2]\n",
    "        isApriori: false\n",
    "        isAveragingKernel: true\n",
    "        stretchVertices: topbottom #options: top, bottom, topbottom, none\n",
    "      obs error:\n",
    "        covariance model: diagonal\n",
    "      get values:\n",
    "        time interpolation: linear\n",
    "```\n",
    "\n",
    "Observation, observation operator specification is listed here. Note that `obsfile` under `obsdatain` points to a tropomi no2 observations file. This file includes measurements from `03Z` to `09Z`, which is throughout our assimilation window. \n",
    "\n",
    "The output file specified under `obsdataout` is the feedback file. It includes observation values and model (background) values at observation location/time or `hofx0` values. `hofx1` is the analysis values (after one outer loop iteration) at observation location/time. `oman` is (observation - analysis) and `ombg` is (observation - background). \n",
    "\n",
    "---\n",
    "\n",
    "```yaml\n",
    "final:\n",
    "  diagnostics:\n",
    "    departures: oman\n",
    "  analysis to latlon:\n",
    "    local interpolator type: oops unstructured grid interpolator\n",
    "    resolution in degrees: 15.0  # low resolution for testing\n",
    "    variables to output: [volume_mixing_ratio_of_no2]\n",
    "    #pressure levels in hPa: [500]\n",
    "    model levels: [71]\n",
    "    #bottom model level: true\n",
    "    frequency: PT3H\n",
    "    datapath: output\n",
    "    exp: 4dvar.c24\n",
    "    type: an\n",
    "    \n",
    "output:\n",
    "  filetype: cube sphere history\n",
    "  provider: geos\n",
    "  datapath: output/\n",
    "  filename: ana.4dvar.c24.%yyyy%mm%dd_%hh%MM%ssz.nc4\n",
    "  first: PT0H\n",
    "  frequency: PT6H\n",
    "```\n",
    "It is possible to write out analysis (and increment) output in lat/lon grid at specific model or pressure level by setting `analysis to latlon` under the `final` section. The lat/lon filename will have a prefix of `exp` and suffix of `latlon.modelLevels.nc`\n",
    "output filename will be `4dvar.c24.an.*Z.latlon.modelLevels.nc`\n",
    "\n",
    "The frequency of analysis output can be set as low as `tstep` under `model`. The frequency of `PT6H` means that there will be two analysis files generated at the beginning and beginning + 6H (end) of the window. \n",
    "\n",
    "---\n",
    "\n",
    "```yaml\n",
    "variational:\n",
    "  minimizer:\n",
    "    algorithm: DRPCG\n",
    "  iterations:\n",
    "  - ninner: 2\n",
    "    gradient norm reduction: 1e-10\n",
    "    test: on\n",
    "    geometry:\n",
    "      akbk: input/geometry_input/akbk72.nc4\n",
    "      npx: 25\n",
    "      npy: 25\n",
    "      npz: 72\n",
    "      layout: [1,2]\n",
    "      field metadata override: input/geometry_input/geos_cf_ewok.yaml\n",
    "    diagnostics:\n",
    "      departures: ombg\n",
    "\n",
    "    linear model:\n",
    "      name: FV3JEDITLM\n",
    "      namelist filename: input/geometry_input/input_geos_c24_p12.nml\n",
    "      linear model namelist filename: input/geometry_input/inputpert_4dvar.nml\n",
    "      tstep: PT15M\n",
    "      tlm variables: *modelvars\n",
    "      lm_do_dyn: 1\n",
    "      lm_do_trb: 0\n",
    "      lm_do_mst: 0\n",
    "      trajectory:\n",
    "        model variables: *modelvars\n",
    "```\n",
    "\n",
    "This section sets up the minimizer for the 4dvar experiment. \n",
    "\n",
    "`ninner` is the number of iterations in the inner loop. For testing is set to 2. In scientific experiments, it is usually set to a larger number like 100. `gradient norm reduction` is the threshold for convergance. \n",
    "\n",
    "In JEDI, you can run the minimizer in a different (coarser) resolution to reduce the computation cost. Here it is set to the same resolution as the analysis. \n",
    "\n",
    "`FV3JEDITLM` is the adjoint of the tangent linear model used for iterative minimization of the cost function. `namelist filename` changes with model resolution and layout. Make sure what is specified in this file matches the 4dvar YAML.\n",
    "\n",
    "`tstep` for `FV3JEDITLM` cannot be smaller than `tstep` in `FV3LM` (or `PSEUDO`) meaning that you need to have model states available at every step of `FV3JEDITLM`. \n",
    "\n",
    "In this example, `tlm variables` and `model variables` under `trajectory` are the same as `model variables` under `FV3LM`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40397c8-7e9e-4c19-bb94-6e749f90c418",
   "metadata": {},
   "source": [
    "To run this application, log into a compute node\n",
    "\n",
    "```bash\n",
    "export JEDIBUILD=/discover/nobackup/mabdiosk/jedi-bundle/build-gnu-spack-1.7.0/bin/\n",
    "export WORKDIR=/gpfsm/dnb33/mabdiosk/garage/applications/var-app\n",
    "\n",
    "/discover/swdev/gmao_SIteam/MPI/openmpi/4.1.6-SLES15/gcc-12.3.0/bin/mpiexec \"-n\" \"12\" \"$JEDIBUILD/fv3jedi_var.x\" \"$WORKDIR/4dvar_geos-cf_fv3lm_c24_p12.yaml\"\n",
    "```\n",
    "\n",
    "The JEDI executable to run variational applications (3D or 4DVar) is `fv3jedi_var.x`\n",
    "\n",
    "Note that here we are requesting 12 processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752bf9ab-492f-472d-a1eb-cb7c4c787e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
